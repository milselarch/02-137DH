{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac35bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "760e157a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c646c9d55b304d34aded7fea8449d710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff404b0f56d4fc0af6df28ad4467882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23002a79e09493280957b60dc626498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_url</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.redd.it/x1p9q9jngae51.jpg</td>\n",
       "      <td>i1j8x7</td>\n",
       "      <td>user reports:\\n    1: It's promoting hate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.redd.it/x1p9q9jngae51.jpg</td>\n",
       "      <td>i1j8x7</td>\n",
       "      <td>This deserves bipartisan support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://i.redd.it/x1p9q9jngae51.jpg</td>\n",
       "      <td>i1j8x7</td>\n",
       "      <td>Proud to have joined this sub when I see posts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://i.redd.it/x1p9q9jngae51.jpg</td>\n",
       "      <td>i1j8x7</td>\n",
       "      <td>A reminder that we are all Americans, and when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.redd.it/x1p9q9jngae51.jpg</td>\n",
       "      <td>i1j8x7</td>\n",
       "      <td>Thanks! From a democrat. I don’t see this cont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              post_url post_id  \\\n",
       "0  https://i.redd.it/x1p9q9jngae51.jpg  i1j8x7   \n",
       "1  https://i.redd.it/x1p9q9jngae51.jpg  i1j8x7   \n",
       "2  https://i.redd.it/x1p9q9jngae51.jpg  i1j8x7   \n",
       "3  https://i.redd.it/x1p9q9jngae51.jpg  i1j8x7   \n",
       "4  https://i.redd.it/x1p9q9jngae51.jpg  i1j8x7   \n",
       "\n",
       "                                             comment  \n",
       "0      user reports:\\n    1: It's promoting hate ...  \n",
       "1                   This deserves bipartisan support  \n",
       "2  Proud to have joined this sub when I see posts...  \n",
       "3  A reminder that we are all Americans, and when...  \n",
       "4  Thanks! From a democrat. I don’t see this cont...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "df = pd.read_csv('../datasets/republican_comments.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78dc16b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           user reports:\\n    1: It's promoting hate ...\n",
      "1                        This deserves bipartisan support\n",
      "2       Proud to have joined this sub when I see posts...\n",
      "3       A reminder that we are all Americans, and when...\n",
      "4       Thanks! From a democrat. I don’t see this cont...\n",
      "                              ...                        \n",
      "3453    wow, how peoples politcal views have changed o...\n",
      "3454    How sadly true, today's Republicans are yester...\n",
      "3455    This is do dumb and not true. Things, people a...\n",
      "3456             Bruh actors and aren’t political figures\n",
      "3457    If Charlie Kirk showed up in 1960 conservative...\n",
      "Name: comment, Length: 3458, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6e154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n",
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c75db1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knight',\n",
       " 'lap',\n",
       " 'survey',\n",
       " 'ma',\n",
       " '##ow',\n",
       " 'noise',\n",
       " 'billy',\n",
       " '##ium',\n",
       " 'shooting',\n",
       " 'guide',\n",
       " 'bedroom',\n",
       " 'priest',\n",
       " 'resistance',\n",
       " 'motor',\n",
       " 'homes',\n",
       " 'sounded',\n",
       " 'giant',\n",
       " '##mer',\n",
       " '150',\n",
       " 'scenes']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show some of the vocabulary that BERT is trained on\n",
    "list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a5e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
